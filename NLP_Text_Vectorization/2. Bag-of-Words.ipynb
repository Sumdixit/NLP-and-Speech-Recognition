{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb88582c-9575-4302-a780-01870c7c5e3e",
   "metadata": {
    "id": "eb88582c-9575-4302-a780-01870c7c5e3e",
    "tags": []
   },
   "source": [
    "# <center> Bag-of-Words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb572300-1aaf-458f-896e-a2115c3fef34",
   "metadata": {},
   "source": [
    "## Overview:\n",
    "\n",
    "The goal is to implement the Bag-of-Words model for text data representation. The notebook introduces the concept and demonstrates its implementation using scikit-learn's `CountVectorizer` to transform text into numerical vectors for machine learning applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719acf7b-587f-4e15-a0b4-e871640155e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <a id= 'b0'> \n",
    "<font size = 4>\n",
    "    \n",
    "**Table of contents:**<br>\n",
    "[1. Introduction](#b1)<br>\n",
    "[2. skLearn-Countvectorizer](#b2)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd12e4da-4b9d-4e4c-a92e-d1b273570385",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <a id = 'b1'>\n",
    "    \n",
    "<font size = 10 color = 'midnightblue'> <b> Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7996fa9f-7899-40ea-8ceb-4624569d65cb",
   "metadata": {},
   "source": [
    "## Bag of Words (BoW) Model\n",
    "\n",
    "A **Bag of Words** (BoW) is a text representation method that describes the occurrence of words within a document, ignoring the grammar and order of the words. In BoW, a document is represented as a vector of word counts. This approach is widely used for feature extraction in various Natural Language Processing (NLP) tasks, such as text classification, sentiment analysis, and information retrieval.\n",
    "\n",
    "### Key Characteristics of BoW:\n",
    "- **Word Occurrence**: It focuses on the frequency of words in a document.\n",
    "- **Order Ignorance**: The order of words is not considered, which simplifies the representation but may lose context.\n",
    "- **High Dimensionality**: The number of features (dimensions) corresponds to the vocabulary size, which can be very large for extensive corpora.\n",
    "\n",
    "### Manual Implementation of Bag of Words\n",
    "\n",
    "Let's illustrate how to manually create a Bag of Words representation using Python. We will demonstrate this with a small corpus of text documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67db7981-403d-4fd8-bd56-20a0e16167b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample documents\n",
    "documents = [\n",
    "    \"I love programming in Python\",\n",
    "    \"Python is great for data science\",\n",
    "    \"I love data science and programming\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d866e3e-ef26-4b73-ab72-04014db2a8a4",
   "metadata": {},
   "source": [
    "#### Step 1: Create a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f083ff9a-2cd7-49b3-9ef8-b3efda41dec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['and', 'data', 'for', 'great', 'i', 'in', 'is', 'love', 'programming', 'python', 'science']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = set()\n",
    "for doc in documents:\n",
    "    words = doc.lower().split()  # Convert to lowercase and split into words\n",
    "    vocabulary.update(words)  # Add words to the vocabulary set\n",
    "\n",
    "# Convert the vocabulary to a sorted list\n",
    "vocabulary = sorted(list(vocabulary))\n",
    "print(\"Vocabulary:\", vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ed6d1-a943-49ca-b934-230ed3b1019a",
   "metadata": {},
   "source": [
    "#### Step 2: Create the BoW representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfff0956-0970-4820-a36e-23c5d3ad9c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words Representation:\n",
      "Document 1: [0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0]\n",
      "Document 2: [0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1]\n",
      "Document 3: [1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "bow_representation = []\n",
    "\n",
    "for doc in documents:\n",
    "    # Initialize a count vector for the current document\n",
    "    count_vector = [0] * len(vocabulary)\n",
    "    words = doc.lower().split()\n",
    "    \n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            index = vocabulary.index(word)\n",
    "            count_vector[index] += 1  # Increment the count for the word in the vector\n",
    "            \n",
    "    bow_representation.append(count_vector)\n",
    "\n",
    "# Displaying the Bag of Words representation\n",
    "print(\"Bag of Words Representation:\")\n",
    "for i, doc_vector in enumerate(bow_representation):\n",
    "    print(f\"Document {i+1}: {doc_vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fcde77b-9a1d-4738-b063-f22c339a247e",
   "metadata": {
    "id": "8fcde77b-9a1d-4738-b063-f22c339a247e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7341fe75-93c7-496d-bc0a-7f8b12dac64c",
   "metadata": {
    "id": "7341fe75-93c7-496d-bc0a-7f8b12dac64c",
    "tags": []
   },
   "source": [
    "<font size = 5 color = seagreen><b> Create a collection dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f241fd2e-01e8-4bcc-a5eb-7d29417e4b0c",
   "metadata": {
    "id": "f241fd2e-01e8-4bcc-a5eb-7d29417e4b0c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    \"The weather today is fantastic, with clear skies and a gentle breeze.\",\n",
    "    \"Reading is a great way to escape reality and immerse oneself in different worlds.\",\n",
    "    \"Climate change is a pressing global issue that requires immediate attention.\",\n",
    "    \"Exercise is crucial for maintaining good physical and mental health.\",\n",
    "    \"Learning a new language can be challenging but incredibly rewarding.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca56466d-e9bb-4fe3-9c42-4e189ce40189",
   "metadata": {},
   "source": [
    "[top](#b0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fba43f-6531-4326-aa88-517394a13093",
   "metadata": {
    "id": "478e971c-edc1-4c8e-8c9a-11c1c707f28f",
    "tags": []
   },
   "source": [
    "## <a id = 'b2'>\n",
    "<font size = 10 color = 'midnightblue'> <b> CountVectorizer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb694ef7-ea1a-49ee-8078-209a32fb0e40",
   "metadata": {
    "id": "478e971c-edc1-4c8e-8c9a-11c1c707f28f"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">    \n",
    "<font size = 4> \n",
    "\n",
    "<b>`CountVectoriser` from sklearn is used to fit the bag-of-words model.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d1874e-a24d-44b4-96cd-ba2c5e92d229",
   "metadata": {
    "id": "c3d1874e-a24d-44b4-96cd-ba2c5e92d229",
    "tags": []
   },
   "source": [
    "<font size = 5 color = seagreen><b>Define a count vectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "877b62af-3804-45e2-b051-e1de9146f261",
   "metadata": {
    "id": "877b62af-3804-45e2-b051-e1de9146f261",
    "tags": []
   },
   "outputs": [],
   "source": [
    "bow = CountVectorizer(max_features=1000, lowercase=True, analyzer='word')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4848af-8a19-4e0e-bb91-658ac95ce258",
   "metadata": {
    "id": "0b4848af-8a19-4e0e-bb91-658ac95ce258"
   },
   "source": [
    "<font size = 5 color = seagreen><b> Fit the bag-of-words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d891668f-6d3c-4be4-a02a-06d02527c6d2",
   "metadata": {
    "id": "d891668f-6d3c-4be4-a02a-06d02527c6d2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "bag_of_words = bow.fit(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41dd377-aedf-4271-be93-20686a6db610",
   "metadata": {
    "id": "f41dd377-aedf-4271-be93-20686a6db610",
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">    \n",
    "<font size = 4> \n",
    "\n",
    "The vectoriser object also returns the feature names for transformation which is the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "502c17ae-1895-4a23-aa1d-66787c1cff98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1701073848710,
     "user": {
      "displayName": "Shubham Pandey",
      "userId": "10645658922718505789"
     },
     "user_tz": -330
    },
    "id": "502c17ae-1895-4a23-aa1d-66787c1cff98",
    "outputId": "c0189d89-93ab-4a99-80d6-0a36b2c4aee6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'attention', 'be', 'breeze', 'but', 'can', 'challenging', 'change', 'clear', 'climate', 'crucial', 'different', 'escape', 'exercise', 'fantastic', 'for', 'gentle', 'global', 'good', 'great', 'health', 'immediate', 'immerse', 'in', 'incredibly', 'is', 'issue', 'language', 'learning', 'maintaining', 'mental', 'new', 'oneself', 'physical', 'pressing', 'reading', 'reality', 'requires', 'rewarding', 'skies', 'that', 'the', 'to', 'today', 'way', 'weather', 'with', 'worlds']\n"
     ]
    }
   ],
   "source": [
    "print(list(bow.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7776955-4139-4cf0-a9dd-17a14842d99c",
   "metadata": {
    "id": "c7776955-4139-4cf0-a9dd-17a14842d99c"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">    \n",
    "<font size = 4> \n",
    "\n",
    "The vectorizer returns a sparse matrix where rows represent each sentence of the dataset and columns correspond to each word in vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15ef2b3b-b9f1-4823-8d17-aaaf6116c54f",
   "metadata": {
    "id": "15ef2b3b-b9f1-4823-8d17-aaaf6116c54f"
   },
   "outputs": [],
   "source": [
    "vector = bow.transform(dataset).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "059e6405-e1f8-478c-bae0-07f7a7c26265",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1701073857254,
     "user": {
      "displayName": "Shubham Pandey",
      "userId": "10645658922718505789"
     },
     "user_tz": -330
    },
    "id": "059e6405-e1f8-478c-bae0-07f7a7c26265",
    "outputId": "f0b9cbad-1bc1-4eeb-e935-c0746a269066",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>attention</th>\n",
       "      <th>be</th>\n",
       "      <th>breeze</th>\n",
       "      <th>but</th>\n",
       "      <th>can</th>\n",
       "      <th>challenging</th>\n",
       "      <th>change</th>\n",
       "      <th>clear</th>\n",
       "      <th>climate</th>\n",
       "      <th>...</th>\n",
       "      <th>rewarding</th>\n",
       "      <th>skies</th>\n",
       "      <th>that</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>today</th>\n",
       "      <th>way</th>\n",
       "      <th>weather</th>\n",
       "      <th>with</th>\n",
       "      <th>worlds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent_1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        and  attention  be  breeze  but  can  challenging  change  clear  \\\n",
       "sent_1    1          0   0       1    0    0            0       0      1   \n",
       "sent_2    1          0   0       0    0    0            0       0      0   \n",
       "sent_3    0          1   0       0    0    0            0       1      0   \n",
       "sent_4    1          0   0       0    0    0            0       0      0   \n",
       "sent_5    0          0   1       0    1    1            1       0      0   \n",
       "\n",
       "        climate  ...  rewarding  skies  that  the  to  today  way  weather  \\\n",
       "sent_1        0  ...          0      1     0    1   0      1    0        1   \n",
       "sent_2        0  ...          0      0     0    0   1      0    1        0   \n",
       "sent_3        1  ...          0      0     1    0   0      0    0        0   \n",
       "sent_4        0  ...          0      0     0    0   0      0    0        0   \n",
       "sent_5        0  ...          1      0     0    0   0      0    0        0   \n",
       "\n",
       "        with  worlds  \n",
       "sent_1     1       0  \n",
       "sent_2     0       1  \n",
       "sent_3     0       0  \n",
       "sent_4     0       0  \n",
       "sent_5     0       0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(vector,\n",
    "             columns= list(bow.get_feature_names_out()),\n",
    "             index = [f'sent_{i}' for i in range(1,len(dataset)+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5add895f-7895-47d7-8fe1-6f454c163256",
   "metadata": {
    "id": "5add895f-7895-47d7-8fe1-6f454c163256"
   },
   "source": [
    "<font size = 5 color = seagreen><b> This vectorised data can be used as features (predictors) to any ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2916d100-f999-4712-9ba4-51c7571f524f",
   "metadata": {
    "id": "4062e41c-c246-4321-9bce-975fee4dab91"
   },
   "source": [
    "[top](#b0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a102e3-26c7-4cdb-8dcd-5c023cd6a8be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
