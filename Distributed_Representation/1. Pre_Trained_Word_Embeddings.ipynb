{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5bkrz_obVSe"
   },
   "source": [
    "# <center> <font size = 24 color = 'steelblue'> <b> Pre-trained word embedding model from gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wIDZixbAFVl6"
   },
   "source": [
    "## Overview:\n",
    "    \n",
    "The objective here is to set up an environment, implement or load a model architecture, and then use a pre-trained embedding model for generating embeddings that can be applied to further tasks in NLP or machine learning applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUsthbX9FVl7"
   },
   "source": [
    "# <a id= 'w0'>\n",
    "<font size = 4>\n",
    "    \n",
    "**Table of contents:**<br>\n",
    "[1. Installation and import of necessary packages](#w1)<br>\n",
    "[2. Model implementation](#w2)<br>\n",
    "[3. Load the embedding model](#w3)<br>\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z89NDA-ToPnT"
   },
   "source": [
    "<font size =5 color = 'seagreen'>\n",
    "    \n",
    "Using a pre-trained word2vec model to look for most similar words.\n",
    "    \n",
    "<b>For this demonstration, `Google News vectors embeddings` are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3mjPTw1bVSk",
    "tags": []
   },
   "source": [
    "##### <a id = 'w1'>\n",
    "<font size = 10 color = 'midnightblue'> <b>Installation and import of necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M67YxxILbVSk",
    "outputId": "7f1de204-f7a6-40d7-b438-b4de7c27fdf8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/site-packages (1.3.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in /usr/local/lib/python3.10/site-packages (4.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/site-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.10/site-packages (from gensim) (1.9.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/site-packages (from gensim) (6.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.10/site-packages (3.5.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/site-packages (from spacy) (8.1.9)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/site-packages (from spacy) (2.4.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/site-packages (from spacy) (6.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from spacy) (58.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from spacy) (22.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy) (2.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "/usr/local/venvs/jupyter/bin/python: No module named spacy\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.3.1\n",
    "!pip install gensim==4.2.0\n",
    "!pip install spacy==3.5.1\n",
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-lg==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl (587.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/site-packages (from en-core-web-lg==3.5.0) (3.5.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.9.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.4.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.4.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (6.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (58.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (22.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2022.6.15)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHiGZuZJbVSm"
   },
   "source": [
    " <font size =5 color = 'seagreen'> <b> Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T11:45:44.132578Z",
     "start_time": "2021-04-03T11:45:44.115562Z"
    },
    "id": "FTpzLd6dvB6Q",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 16:02:11.977604: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-12 16:02:12.019102: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-12 16:02:14.947624: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOC-NOTICE: GPU memory for this assignment is capped at 1024MiB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "# To suppress warnings\n",
    "import warnings #This module ignores the various types of warnings generated\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FywZC1sWFVl9"
   },
   "source": [
    "[top](#w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHsoqTFsbVSn",
    "tags": []
   },
   "source": [
    " ##### <a id = 'w2'>\n",
    "<font size = 10 color = 'midnightblue'> <b>  Model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "citHyxUNFVl9",
    "tags": []
   },
   "source": [
    "<font size = 5 color = pwdrblue> <b> Get the word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the model: 3000000\n",
      "[ 2.05078125e-01  7.85827637e-04  3.54003906e-02  1.00585938e-01\n",
      " -5.44433594e-02  1.53320312e-01  2.55859375e-01 -2.18750000e-01\n",
      " -3.31115723e-03  2.09960938e-01 -2.07031250e-01  1.77001953e-02\n",
      "  4.29687500e-02 -2.01171875e-01 -1.57226562e-01  1.88476562e-01\n",
      " -3.73535156e-02  2.36816406e-02 -2.63671875e-01 -1.33789062e-01\n",
      "  2.23632812e-01  2.05078125e-01 -5.83496094e-02 -3.11279297e-02\n",
      "  4.92095947e-04  2.36328125e-01  1.16699219e-01  4.24804688e-02\n",
      " -1.33789062e-01  1.84570312e-01  5.02929688e-02 -6.00585938e-02\n",
      " -6.22558594e-02  7.61718750e-02  1.48437500e-01  6.10351562e-02\n",
      "  6.39648438e-02 -2.73437500e-01  1.48437500e-01  8.15429688e-02\n",
      "  1.57226562e-01 -2.63671875e-02 -1.10839844e-01  3.24707031e-02\n",
      " -6.93359375e-02 -3.29589844e-02 -1.34765625e-01  4.32128906e-02\n",
      " -1.42578125e-01 -2.50000000e-01  9.86328125e-02 -1.10839844e-01\n",
      " -6.98242188e-02 -2.46093750e-01  1.65039062e-01 -9.81445312e-02\n",
      " -1.71875000e-01 -1.20117188e-01  1.21582031e-01  1.50390625e-01\n",
      "  4.15039062e-02  2.16064453e-02 -8.20312500e-02 -4.98046875e-02\n",
      " -6.49414062e-02  8.49609375e-02 -6.98242188e-02  3.32031250e-02\n",
      "  1.43554688e-01 -1.31835938e-01  1.50756836e-02  1.08398438e-01\n",
      "  1.29882812e-01 -5.95703125e-02  6.59179688e-02 -7.17773438e-02\n",
      " -1.56250000e-01  1.05957031e-01  7.04956055e-03  1.22070312e-01\n",
      "  1.57226562e-01  2.97851562e-02  8.54492188e-02 -1.17675781e-01\n",
      " -8.88671875e-02  3.71093750e-02 -6.01196289e-03  4.18090820e-03\n",
      "  1.60156250e-01  1.57470703e-02  1.66992188e-01  1.69677734e-02\n",
      " -4.56542969e-02  9.86328125e-02  1.65039062e-01  7.76367188e-02\n",
      "  1.04003906e-01  1.53320312e-01 -6.95800781e-03 -9.42382812e-02\n",
      " -1.15722656e-01 -1.65039062e-01 -2.41210938e-01  8.69140625e-02\n",
      "  1.38671875e-01 -1.03027344e-01  1.95312500e-02 -6.88476562e-02\n",
      "  3.10058594e-02  7.51953125e-02 -1.34765625e-01 -6.68945312e-02\n",
      " -1.31835938e-01  8.15429688e-02  1.60156250e-01 -6.83593750e-02\n",
      "  7.37304688e-02  9.47265625e-02  9.08203125e-02  9.32617188e-02\n",
      "  1.64794922e-02 -2.71484375e-01 -4.58984375e-02 -1.09863281e-01\n",
      " -3.26538086e-03  1.80664062e-01 -3.35693359e-03  4.85229492e-03\n",
      "  3.76953125e-01  1.33056641e-02 -1.78710938e-01 -3.39843750e-01\n",
      " -2.50244141e-02  1.87500000e-01  2.47070312e-01 -1.13281250e-01\n",
      " -1.45507812e-01 -1.64062500e-01 -1.84570312e-01  1.67968750e-01\n",
      "  4.39453125e-01 -8.78906250e-03  4.73632812e-02  1.64062500e-01\n",
      "  1.64062500e-01 -3.61328125e-02 -7.08007812e-02  1.33056641e-02\n",
      " -1.96289062e-01 -1.24511719e-02  1.51367188e-01 -9.03320312e-03\n",
      " -1.77734375e-01 -8.25195312e-02 -6.93359375e-02  5.59082031e-02\n",
      " -1.28906250e-01  1.15234375e-01 -4.68750000e-02 -1.70898438e-01\n",
      "  4.19921875e-02 -3.83300781e-02  1.53320312e-01 -5.83496094e-02\n",
      "  6.22558594e-03  2.18750000e-01  1.10351562e-01 -1.53320312e-01\n",
      "  1.77621841e-05  1.28906250e-01 -1.92382812e-01  1.88476562e-01\n",
      " -2.14843750e-01 -5.27343750e-02 -5.71289062e-02  1.21093750e-01\n",
      "  8.05664062e-02 -1.51367188e-01  8.44726562e-02  5.63964844e-02\n",
      " -1.13769531e-01 -1.35742188e-01  8.25195312e-02 -5.76171875e-02\n",
      "  1.19140625e-01  2.54821777e-03 -1.09252930e-02  2.39257812e-02\n",
      " -2.57568359e-02 -1.74560547e-02 -2.16796875e-01  5.63964844e-02\n",
      "  1.62109375e-01 -1.42578125e-01 -1.71875000e-01  2.50244141e-02\n",
      "  6.78710938e-02 -7.71484375e-02  9.96093750e-02 -1.25000000e-01\n",
      "  1.34277344e-02  2.20703125e-01  4.69970703e-03  4.98046875e-02\n",
      " -1.75781250e-01  1.23291016e-02 -1.97265625e-01 -2.09960938e-02\n",
      "  3.90625000e-02 -7.99560547e-03  2.40234375e-01  3.29589844e-02\n",
      " -1.53320312e-01  7.08007812e-02 -2.25585938e-01 -1.11694336e-02\n",
      "  2.55859375e-01  6.39648438e-02 -2.04101562e-01  2.69531250e-01\n",
      " -9.32617188e-02  6.03027344e-02  4.90722656e-02 -3.07617188e-02\n",
      "  5.22460938e-02 -2.89306641e-02  9.96093750e-02  2.08984375e-01\n",
      "  3.58886719e-02 -9.37500000e-02 -8.93554688e-02 -1.21582031e-01\n",
      "  3.44238281e-02 -1.00585938e-01  4.58984375e-02 -3.61328125e-02\n",
      "  8.59375000e-02  4.41894531e-02  1.72851562e-01  1.37329102e-02\n",
      " -2.58789062e-02 -9.27734375e-02  1.58203125e-01  2.45361328e-02\n",
      "  8.74023438e-02 -1.38671875e-01 -1.83593750e-01  1.35742188e-01\n",
      " -1.34765625e-01 -4.51660156e-02  1.04003906e-01  3.12500000e-02\n",
      " -9.52148438e-02 -6.22558594e-02  1.99890137e-03 -4.34570312e-02\n",
      "  1.30615234e-02  1.46484375e-01 -1.24023438e-01  3.49121094e-02\n",
      " -1.12304688e-01  1.49414062e-01 -1.71875000e-01 -9.81445312e-02\n",
      "  2.11914062e-01  4.37011719e-02  4.22363281e-02  3.71093750e-02\n",
      " -1.61132812e-01  2.91748047e-02  7.35473633e-03 -2.44140625e-02\n",
      " -2.28271484e-02  5.43212891e-03 -6.44531250e-02 -3.29589844e-02\n",
      " -1.05468750e-01 -7.22656250e-02  2.85644531e-02 -8.39843750e-02\n",
      "  8.05664062e-02  6.25000000e-02 -8.34960938e-02 -1.11816406e-01\n",
      " -4.43359375e-01 -5.07812500e-02 -1.48437500e-01  1.83593750e-01\n",
      " -6.59179688e-02  9.37500000e-02 -7.61718750e-02 -5.83496094e-02\n",
      " -2.89062500e-01 -1.41601562e-01 -7.71484375e-02 -8.78906250e-02\n",
      "  9.71679688e-02  1.29882812e-01  1.25976562e-01  9.71679688e-02]\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "w2v_model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "# Check the model\n",
    "print(f\"Number of words in the model: {len(w2v_model.key_to_index)}\")\n",
    "print(w2v_model['example'])  # Replace 'example' with an actual word in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKLHtMpPbVSp"
   },
   "source": [
    "<font size = 5 color = pwdrblue> <b> Check number of words in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HE4PlWlBbVSp",
    "outputId": "f74f60df-c572-4b40-df11-67846adafb7c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocabulary:  3000000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of words in vocabulary: \",len(w2v_model.index_to_key)) #Number of words in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zHa5kXYCbVSp",
    "outputId": "d459298d-54bc-446d-cfc7-916b8a13bb9c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few words of the vocabulary :\n",
      "['</s>', 'in', 'for', 'that', 'is', 'on', '##', 'The', 'with', 'said', 'was', 'the', 'at', 'not', 'as', 'it', 'be', 'from', 'by', 'are']\n"
     ]
    }
   ],
   "source": [
    "print(f\"First few words of the vocabulary :\\n{ w2v_model.index_to_key[:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wb-rFKMzbVSp"
   },
   "source": [
    "<font size = 5 color = pwdrblue> <b> Examine the model to extract most similar words for a given word like `joyful`, `solid`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding `most_similar` Method\n",
    "\n",
    "- **Function Purpose**: The `most_similar` method is a built-in function of the `KeyedVectors` class from the Gensim library. Its primary purpose is to find and return the top N most similar words to a given word based on their embeddings.\n",
    "\n",
    "- **Input**: In your case, the input is the string `'joyful'`. This is the word for which you want to find similar words.\n",
    "\n",
    "- **Output**: The method returns a list of tuples. Each tuple contains a similar word and its corresponding similarity score. For example:\n",
    "  ```python\n",
    "  [('happy', 0.85), ('joyous', 0.78), ('cheerful', 0.75), ...]\n",
    "  ```  \n",
    "## How Similarity is Calculated\n",
    "\n",
    "- **Cosine Similarity**: The similarity is calculated using cosine similarity, which measures the cosine of the angle between two non-zero vectors in an inner product space. This value ranges from -1 to 1, where:\n",
    "  - 1 means the vectors point in the same direction (completely similar),\n",
    "  - 0 means they are orthogonal (not similar), and\n",
    "  - -1 means they point in opposite directions.\n",
    "\n",
    "- **Vector Representation**: Each word, including \"joyful,\" is represented as a high-dimensional vector. The model was trained on large corpora of text, which allows it to capture semantic relationships based on word co-occurrences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T11:46:29.336184Z",
     "start_time": "2021-04-03T11:46:26.529524Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZhJ_488PoPnr",
    "outputId": "424fc362-bddf-4998-b354-510907b6e1aa",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('joyous', 0.818248987197876),\n",
       " ('Besnik_Berisha_Pristina', 0.6848508715629578),\n",
       " ('joy', 0.6633967757225037),\n",
       " ('joyousness', 0.6440029740333557),\n",
       " ('exuberant', 0.6130944490432739),\n",
       " ('uplifting', 0.593187153339386),\n",
       " ('old_demonstrator_Juliya', 0.592427134513855),\n",
       " ('sorrowful', 0.5822992324829102),\n",
       " ('cheerful', 0.5811519026756287),\n",
       " ('indescribable_joy', 0.581040620803833)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar('joyful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T11:46:29.509126Z",
     "start_time": "2021-04-03T11:46:29.337187Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G1Or5oG5oPn1",
    "outputId": "7b062723-fc1b-4315-dff8-486d462bf795",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('travel', 0.6577276587486267),\n",
       " ('Adventure_Travel', 0.636359453201294),\n",
       " ('Travel_Agent', 0.608870804309845),\n",
       " ('Aol_Autos', 0.5961860418319702),\n",
       " ('Destinations', 0.5935966968536377),\n",
       " ('Vacations', 0.5759146213531494),\n",
       " ('Vantage_Deluxe', 0.573976993560791),\n",
       " ('Travel_Destinations', 0.5731626152992249),\n",
       " ('Travel_Agents', 0.5724309086799622),\n",
       " ('Escorted_Tours', 0.557145893573761)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar('Travel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ojZH2zXjbVSq",
    "outputId": "3246e881-4607-471c-a144-578aff223c5b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('traveling', 0.6823130249977112),\n",
       " ('Travel', 0.6577276587486267),\n",
       " ('travelers', 0.5849088430404663),\n",
       " ('trips', 0.5770835280418396),\n",
       " ('travels', 0.5704988241195679),\n",
       " ('trip', 0.569098174571991),\n",
       " ('journeys', 0.5535728335380554),\n",
       " ('airfare', 0.5398489832878113),\n",
       " ('Travelling', 0.5369202494621277),\n",
       " ('Traveling', 0.5305294394493103)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar('travel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2Vy8qR8bVSr"
   },
   "source": [
    "<font size = 5 color = seagreen> <b> The below snippet can be used to manage the error if word doesnt exist in corpus and check similarity for multiple words:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2Vy8qR8bVSr"
   },
   "source": [
    "- The provided code snippet allows users to input a word and retrieve the most similar words based on the Word2Vec model. The code includes error handling to manage situations where the input word is not present in the model's vocabulary.\n",
    "\n",
    "### Error Management\n",
    "- Try-Except Block:\n",
    "    - The code uses a try block to attempt to retrieve similar words for the input word. If the word is not found in the model's vocabulary, an exception is raised.\n",
    "    - The except block catches this exception and provides a user-friendly message: \"Word does not exist in vocabulary!\". This ensures that the program does not crash and allows the user to enter another word.\n",
    "### Similarity Calculation\n",
    "- Cosine Similarity:\n",
    "\n",
    "    - The most_similar method calculates similarity using cosine similarity. This mathematical measure determines how similar two vectors (in this case, word embeddings) are by computing the cosine of the angle between them.\n",
    "    - If two word vectors point in the same direction, their cosine similarity is close to 1. If they are orthogonal (i.e., unrelated), the similarity is close to 0, and if they point in opposite directions, the similarity is -1.\n",
    "\n",
    "### Word Vector Representation:\n",
    "\n",
    "- Each word is represented as a high-dimensional vector. The Word2Vec model is trained on large corpora of text, allowing it to learn contextual relationships between words based on their occurrences in similar contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_Wk89c0bVSr",
    "outputId": "77b37ffd-a779-4b9d-f73d-445b209dc989",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a word to get similar words:  happy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'happy' :\n",
      "\n",
      "('glad', 0.7408890724182129)\n",
      "('pleased', 0.6632170677185059)\n",
      "('ecstatic', 0.6626912355422974)\n",
      "('overjoyed', 0.6599286794662476)\n",
      "('thrilled', 0.6514049172401428)\n",
      "('satisfied', 0.6437949538230896)\n",
      "('proud', 0.636042058467865)\n",
      "('delighted', 0.627237856388092)\n",
      "('disappointed', 0.6269949674606323)\n",
      "('excited', 0.6247665286064148)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to continue? (Y/N) :  n\n"
     ]
    }
   ],
   "source": [
    "inp = \"y\"\n",
    "while inp.lower() == 'y':\n",
    "    word = input(\"Enter a word to get similar words: \")\n",
    "    try :\n",
    "        print(f\"Most similar words to '{word}' :\\n\")\n",
    "        for t in w2v_model.most_similar(word):\n",
    "            print(t)\n",
    "        print('\\n')\n",
    "    except :\n",
    "        print('Word does not exists in vocabulary!')\n",
    "    inp = input(\"Do you want to continue? (Y/N) : \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9qhi6UmbVSr",
    "tags": []
   },
   "source": [
    "<font size = 5 color = pwdrblue> <b>  Get the word vector of any term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Word Vector?\n",
    "\n",
    "### Definition:\n",
    "A word vector is a numerical representation of a word in a high-dimensional space. In the context of Word2Vec, each word from the vocabulary is mapped to a vector of fixed length (e.g., 300 dimensions). These vectors are generated through training on large corpora of text, allowing the model to capture the contextual meaning of words based on their usage in sentences.\n",
    "\n",
    "### Significance:\n",
    "Word vectors are crucial in natural language processing (NLP) because they allow machines to understand and manipulate human language in a more meaningful way. Similar words will have vectors that are closer together in the vector space, enabling the model to identify semantic relationships, such as synonyms or related concepts. For example, \"beautiful\" might be close to words like \"pretty,\" \"lovely,\" or \"gorgeous\" in the vector space.\n",
    "\n",
    "### Dimensionality:\n",
    "The dimensionality of word vectors (e.g., 100, 200, 300 dimensions) determines the richness of the word representations. Higher dimensions may capture more nuanced relationships but also increase computational complexity.\n",
    "\n",
    "### Example of Usage:\n",
    "When you execute `w2v_model['beautiful']`, you are accessing the vector associated with the word \"beautiful.\" This vector can be used in various NLP tasks, including:\n",
    "\n",
    "- **Similarity calculations**: Comparing how similar \"beautiful\" is to other words.\n",
    "- **Clustering**: Grouping similar words based on their vectors.\n",
    "- **Machine learning models**: Using word vectors as input features for models that perform tasks like sentiment analysis, classification, or information retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T11:46:30.275722Z",
     "start_time": "2021-04-03T11:46:30.266713Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rtQiYOR9oPn_",
    "outputId": "2bc507b6-c546-49ad-a1b5-789d1e6b86ec",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01831055,  0.05566406, -0.01153564,  0.07275391,  0.15136719,\n",
       "       -0.06176758,  0.20605469, -0.15332031, -0.05908203,  0.22851562,\n",
       "       -0.06445312, -0.22851562, -0.09472656, -0.03344727,  0.24707031,\n",
       "        0.05541992, -0.00921631,  0.1328125 , -0.15429688,  0.08105469,\n",
       "       -0.07373047,  0.24316406,  0.12353516, -0.09277344,  0.08203125,\n",
       "        0.06494141,  0.15722656,  0.11279297, -0.0612793 , -0.296875  ,\n",
       "       -0.13378906,  0.234375  ,  0.09765625,  0.17773438,  0.06689453,\n",
       "       -0.27539062,  0.06445312, -0.13867188, -0.08886719,  0.171875  ,\n",
       "        0.07861328, -0.10058594,  0.23925781,  0.03808594,  0.18652344,\n",
       "       -0.11279297,  0.22558594,  0.10986328, -0.11865234,  0.02026367,\n",
       "        0.11376953,  0.09570312,  0.29492188,  0.08251953, -0.05444336,\n",
       "       -0.0090332 , -0.0625    , -0.17578125, -0.08154297,  0.01062012,\n",
       "       -0.04736328, -0.08544922, -0.19042969, -0.30273438,  0.07617188,\n",
       "        0.125     , -0.05932617,  0.03833008, -0.03564453,  0.2421875 ,\n",
       "        0.36132812,  0.04760742,  0.00631714, -0.03088379, -0.13964844,\n",
       "        0.22558594, -0.06298828, -0.02636719,  0.1171875 ,  0.33398438,\n",
       "       -0.07666016, -0.06689453,  0.04150391, -0.15136719, -0.22460938,\n",
       "        0.03320312, -0.15332031,  0.07128906,  0.16992188,  0.11572266,\n",
       "       -0.13085938,  0.12451172, -0.20410156,  0.04736328, -0.296875  ,\n",
       "       -0.17480469,  0.00872803, -0.04638672,  0.10791016, -0.203125  ,\n",
       "       -0.27539062,  0.2734375 ,  0.02563477, -0.11035156,  0.0625    ,\n",
       "        0.1953125 ,  0.16015625, -0.13769531, -0.09863281, -0.1953125 ,\n",
       "       -0.22851562,  0.25390625,  0.00915527, -0.03857422,  0.3984375 ,\n",
       "       -0.1796875 ,  0.03833008, -0.24804688,  0.03515625,  0.03881836,\n",
       "        0.03442383, -0.04101562,  0.20214844, -0.03015137, -0.09619141,\n",
       "        0.11669922, -0.06738281,  0.0625    ,  0.10742188,  0.25585938,\n",
       "       -0.21777344,  0.05639648, -0.0065918 ,  0.16113281,  0.11865234,\n",
       "       -0.03088379, -0.11572266,  0.02685547,  0.03100586,  0.09863281,\n",
       "        0.05883789,  0.00634766,  0.11914062,  0.07324219, -0.01586914,\n",
       "        0.18457031,  0.05322266,  0.19824219, -0.22363281, -0.25195312,\n",
       "        0.15039062,  0.22753906,  0.05737305,  0.16992188, -0.22558594,\n",
       "        0.06494141,  0.11914062, -0.06640625, -0.10449219, -0.07226562,\n",
       "       -0.16992188,  0.0625    ,  0.14648438,  0.27148438, -0.02172852,\n",
       "       -0.12695312,  0.18457031, -0.27539062, -0.36523438, -0.03491211,\n",
       "       -0.18554688,  0.23828125, -0.13867188,  0.00296021,  0.04272461,\n",
       "        0.13867188,  0.12207031,  0.05957031, -0.22167969, -0.18945312,\n",
       "       -0.23242188, -0.28710938, -0.00866699, -0.16113281, -0.24316406,\n",
       "        0.05712891, -0.06982422,  0.00053406, -0.10302734, -0.13378906,\n",
       "       -0.16113281,  0.11621094,  0.31640625, -0.02697754, -0.01574707,\n",
       "        0.11425781, -0.04174805,  0.05908203,  0.02661133, -0.08642578,\n",
       "        0.140625  ,  0.09228516, -0.25195312, -0.31445312, -0.05688477,\n",
       "        0.01031494,  0.0234375 , -0.02331543, -0.08056641,  0.01269531,\n",
       "       -0.34179688,  0.17285156, -0.16015625,  0.07763672, -0.03088379,\n",
       "        0.11962891,  0.11767578,  0.20117188, -0.01940918,  0.02172852,\n",
       "        0.23046875,  0.28125   , -0.17675781,  0.02978516,  0.08740234,\n",
       "       -0.06176758,  0.00939941, -0.09277344, -0.203125  ,  0.13085938,\n",
       "       -0.13671875, -0.00500488, -0.04296875,  0.12988281,  0.3515625 ,\n",
       "        0.0402832 , -0.12988281, -0.03173828,  0.28515625,  0.18261719,\n",
       "        0.13867188, -0.16503906, -0.26171875, -0.04345703,  0.0100708 ,\n",
       "        0.08740234,  0.00421143, -0.1328125 , -0.17578125, -0.04321289,\n",
       "       -0.015625  ,  0.16894531,  0.25      ,  0.37109375,  0.19921875,\n",
       "       -0.36132812, -0.10302734, -0.20800781, -0.20117188, -0.01519775,\n",
       "       -0.12207031, -0.12011719, -0.07421875, -0.04345703,  0.14160156,\n",
       "        0.15527344, -0.03027344, -0.09326172, -0.04589844,  0.16796875,\n",
       "       -0.03027344,  0.09179688, -0.10058594,  0.20703125,  0.11376953,\n",
       "       -0.12402344,  0.04003906,  0.06933594, -0.34570312,  0.03881836,\n",
       "        0.16210938,  0.05761719, -0.12792969, -0.05810547,  0.03857422,\n",
       "       -0.11328125, -0.1953125 , -0.28125   , -0.13183594,  0.15722656,\n",
       "       -0.09765625,  0.09619141, -0.09960938, -0.00285339, -0.03637695,\n",
       "        0.15429688,  0.06152344, -0.34570312,  0.11083984,  0.03344727],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model['beautiful']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8BIHwnvbVSr"
   },
   "source": [
    "<font size = 5 color = pwdrblue> <b>  Get the embeddings for a complete text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLtL5qIHFVl-"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<font size = 4>\n",
    "    \n",
    "- A simple way is to just sum or average the embeddings for individual words.\n",
    "- Let us see a small example using another NLP library Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnleQzlhFVl-",
    "tags": []
   },
   "source": [
    "[top](#w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKVD-NWRbVSs"
   },
   "source": [
    " ##### <a id = 'w3'>\n",
    "<font size = 10 color = 'midnightblue'> <b> Load the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OVkHPOxSbVSs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the english embedding\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Axetn20PbVSs",
    "outputId": "ca77a7f4-0c63-491b-fa9c-8db24d039b00",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.7266681e+00 -1.7625976e+00 -1.5062932e+00  1.0659857e+00\n",
      "  5.1311164e+00  2.9111406e-02  6.2394553e-01  3.1948249e+00\n",
      " -1.8934714e+00 -2.1929944e+00  4.5006537e+00  2.4514868e+00\n",
      " -4.5428243e+00  1.2644234e+00 -2.3397674e-01  2.9398270e+00\n",
      "  2.2581408e+00  2.9875667e+00 -1.9645262e+00 -2.4424388e+00\n",
      "  1.7411895e+00  1.2703067e+00 -2.6838844e+00 -7.6376837e-01\n",
      " -1.1830875e+00 -2.5485353e+00 -8.7953758e-01 -2.0849400e+00\n",
      "  1.1747426e+00 -1.0882088e-01 -6.1871994e-01 -3.4561667e-01\n",
      "  7.8869581e-01 -2.6599169e-02 -1.5586964e+00 -1.4661268e+00\n",
      "  1.4246036e+00  2.3581977e+00 -8.0672759e-01 -6.2371916e-01\n",
      "  9.9842834e-01 -3.4404168e-01 -1.5362601e+00  9.4676696e-02\n",
      " -1.9323992e+00 -7.1922398e-01  2.5718352e-02 -1.9375043e+00\n",
      "  1.4668162e-01  3.8322163e-01 -2.0981150e+00  2.1650372e+00\n",
      "  3.3772334e-01 -4.2974758e+00  1.0157917e-01  1.6267353e+00\n",
      " -1.6143967e+00  1.0875858e+00  6.1909851e-02 -1.1584975e+00\n",
      "  2.1183548e+00  3.7791324e-01 -6.0935080e-01  3.5485086e-01\n",
      "  3.9455414e+00  9.8692089e-01 -1.2834917e+00 -3.4410141e+00\n",
      "  9.7502166e-01  1.6017942e+00 -1.9368897e-01  4.2905083e-01\n",
      " -1.3932709e+00  1.5001503e-01 -1.5039171e+00 -6.5552580e-01\n",
      " -2.4923337e+00  1.5570592e+00 -1.7632390e+00  5.2243167e-01\n",
      " -3.9525087e+00 -1.0315570e+00 -1.2538857e+00  1.7294065e+00\n",
      "  1.1091509e+00 -2.5341702e-01 -2.8669672e+00 -3.2265272e+00\n",
      "  2.2924669e+00 -4.2600247e-01 -1.4107265e+00 -5.5130166e-01\n",
      "  2.2111151e+00 -3.2799351e+00 -6.3162750e-01 -7.6203126e-01\n",
      "  1.3431066e+00 -5.6182581e-01  1.4038252e+00  2.4100933e+00\n",
      "  3.6230161e+00  2.7147928e-01  2.4008119e+00  4.1939292e+00\n",
      "  1.1672481e+00  4.4181752e+00  4.1146335e-01 -2.0870671e+00\n",
      "  5.1979136e-01 -3.4902763e+00  2.1658418e+00  5.8303487e-01\n",
      " -2.9185467e+00 -2.8126508e-01  2.5501409e+00  6.3458419e-01\n",
      " -1.0117658e+00 -1.1578075e+00 -8.5197926e-01 -4.1829677e+00\n",
      " -1.5276572e+00 -3.9803498e+00  2.1711788e+00 -6.7373830e-01\n",
      " -4.5948091e-01 -3.4803560e+00  1.5315713e+00 -3.9766691e+00\n",
      "  2.9695959e+00 -2.3595927e+00 -3.7356005e+00  1.4426850e+00\n",
      "  3.9360421e+00 -3.0745327e-01 -1.5113864e+00 -5.6260973e-01\n",
      " -3.0552406e+00 -1.6270550e+00  1.0417984e+00  3.5536328e-01\n",
      " -3.7639919e-01 -6.0222334e-01 -1.0261558e+00 -2.3647362e-01\n",
      "  2.7650766e+00  1.4151083e+00 -2.5185945e+00 -5.0594085e-01\n",
      "  2.9740045e+00  3.2241075e+00  1.3551650e+00  1.8627157e+00\n",
      "  1.5392338e-01  1.3582484e+00 -2.9807537e+00  1.9487251e+00\n",
      "  2.6029832e+00 -8.9646798e-01 -3.3144255e+00 -2.8961525e+00\n",
      " -9.9295163e-01 -1.1778884e+00  1.7726301e+00  1.9355735e+00\n",
      " -2.0434916e+00 -2.4482760e+00 -3.0833342e+00  1.1387933e+00\n",
      "  6.0259581e-01  2.9754165e-01 -1.4316250e+00 -1.5416679e+00\n",
      "  1.6194592e+00  5.1059574e-01  2.6982768e+00  1.6854300e+00\n",
      "  5.8965141e-01 -1.1440964e+00 -3.5602834e+00 -1.7811991e+00\n",
      " -2.9919107e+00 -2.9456082e-01  9.7525835e-02 -2.2692792e+00\n",
      " -1.4685866e+00  3.3857945e-01 -1.1875559e+00  7.0497058e-02\n",
      " -1.4668633e+00 -3.1941731e-03 -1.3942013e+00 -2.9097278e+00\n",
      "  4.1185807e-02 -2.0823450e+00  1.3110468e+00  1.1440666e+00\n",
      " -4.1565957e+00 -7.3004669e-01  1.4931825e+00 -1.9961982e+00\n",
      " -1.3480482e+00 -1.0222825e+00  9.3771452e-01  8.8263310e-02\n",
      "  3.5905216e+00 -8.6647771e-05 -5.0818748e+00  2.5274675e+00\n",
      " -2.4370559e-01 -2.2943747e-01  6.9915700e-01  1.2922535e+00\n",
      " -1.8165444e+00  1.3418299e+00  5.8115095e-01  2.1385124e+00\n",
      "  1.8411165e+00 -3.8225954e+00 -4.3089080e-01  1.8897734e+00\n",
      " -1.3684449e+00  2.5087714e+00 -1.0074176e+00 -1.0187919e-01\n",
      " -9.3343073e-01 -6.5660745e-01  1.5595359e+00  2.5001400e+00\n",
      "  1.0999416e+00 -1.1357063e+00  3.9589558e+00 -2.2174022e+00\n",
      " -2.1685550e+00  2.2414343e+00  3.9193504e+00 -7.7047586e-02\n",
      " -2.3908021e+00 -9.4854750e-02 -4.0570855e-01 -4.4463325e-02\n",
      " -1.1091051e+00 -1.4069992e+00  2.2076602e-01 -1.1433526e+00\n",
      " -2.7802041e+00  9.3222994e-01 -3.1217887e+00  7.8700346e-01\n",
      " -1.0541350e+00  3.1630163e+00  1.1033279e+00 -2.3616300e+00\n",
      " -3.4669726e+00 -1.4821582e-01  8.0403209e-01 -2.6251781e+00\n",
      "  2.7524951e+00 -5.5717415e-01  7.9000169e-01  5.5097753e-01\n",
      " -1.1014374e+00  4.0894608e+00  3.1717100e+00  2.2914751e+00\n",
      "  2.1299984e+00 -5.0715500e-01 -5.3469163e-01  2.2896893e+00\n",
      "  1.2136147e-01  1.1145949e-02  5.2876997e-01 -1.0431784e+00\n",
      "  2.1095450e+00 -3.3112437e-02 -1.4575499e-01 -5.8272082e-01\n",
      "  2.0373499e+00 -1.4144000e+00 -3.1867668e-01 -1.9952877e-01\n",
      "  2.4430563e+00  1.1186633e+00  1.0303916e+00  2.1447675e+00\n",
      "  1.3553696e+00 -1.6283808e+00 -1.4980131e+00  2.6316612e+00\n",
      " -1.8742118e+00  1.1446301e+00  2.5621176e-01 -4.0655842e-01\n",
      " -1.8948499e+00 -8.7900811e-01 -1.4839636e+00  4.2525920e-01\n",
      " -4.0123343e-02 -3.4619598e+00 -4.9580702e-01  2.1418800e+00]\n"
     ]
    }
   ],
   "source": [
    "# Create a model object\n",
    "mydoc = nlp(\"Artificial intelligence revolutionizes industries by enhancing automation and decision-making.\")\n",
    "\n",
    "# Get the averaged vector for the entire sentence\n",
    "print(mydoc.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
